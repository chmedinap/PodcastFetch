{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PodcastFetch Analysis\n",
        "\n",
        "This notebook is for analyzing and working with podcast data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import standard library\n",
        "import os\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "\n",
        "# Import third-party libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import PodcastFetch modules\n",
        "from podcast_fetch import config\n",
        "from podcast_fetch import (\n",
        "    # Data functions\n",
        "    normalize,\n",
        "    collect_data,\n",
        "    summarise_podcasts,\n",
        "    get_rss_from_apple_podcast,\n",
        "    normalize_feed_url,\n",
        "    get_podcast_title,\n",
        "    get_apple_podcast_info,\n",
        "    # Database functions\n",
        "    is_valid_database,\n",
        "    get_db_connection,\n",
        "    clean_dataframe_for_sqlite,\n",
        "    table_exists,\n",
        "    summary_exists,\n",
        "    has_downloaded_episodes,\n",
        "    verify_downloaded_files_exist,\n",
        "    add_download_columns_to_table,\n",
        "    update_download_info,\n",
        "    update_all_tables_with_download_columns,\n",
        "    add_podcast_image_url_to_summary,\n",
        "    add_indexes_to_table,\n",
        "    update_all_tables_with_indexes,\n",
        "    explain_query_plan,\n",
        "    # Download functions\n",
        "    sanitize_filename,\n",
        "    show_podcast_summary,\n",
        "    download_all_episodes,\n",
        "    download_last_episode,\n",
        "    update_summary,\n",
        ")\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use(config.PLOTTING_STYLE)\n",
        "sns.set_palette(config.SEABORN_PALETTE)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Using database: {config.DB_PATH}\")\n",
        "print(f\"Downloads folder: {config.DOWNLOADS_FOLDER}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the feeds.txt file and save it as a list of strings\n",
        "# Automatically handles both RSS feed URLs and Apple Podcast links\n",
        "# - RSS feed URLs are used directly\n",
        "# - Apple Podcast links are automatically converted to RSS feed URLs\n",
        "# - Podcast titles are fetched and displayed for each feed\n",
        "with open(config.FEEDS_FILE, 'r') as file:\n",
        "    feeds = file.readlines()\n",
        "\n",
        "# Strip newlines and normalize feed URLs, getting podcast titles\n",
        "normalized_feeds = []\n",
        "feed_info = []  # Store (rss_url, title) tuples\n",
        "apple_podcast_count = 0\n",
        "rss_feed_count = 0\n",
        "\n",
        "for feed in feeds:\n",
        "    feed = feed.strip()\n",
        "    if not feed or feed.startswith('#'):  # Skip empty lines and comments\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        # Check if it's an Apple Podcast link\n",
        "        is_apple_podcast = 'podcasts.apple.com' in feed or 'itunes.apple.com' in feed\n",
        "        \n",
        "        if is_apple_podcast:\n",
        "            # Convert Apple Podcast link to RSS feed and get title\n",
        "            print(f\"üì± Detected Apple Podcast link, converting to RSS feed...\")\n",
        "            print(f\"   Apple Podcast: {feed}\")\n",
        "            try:\n",
        "                rss_url, podcast_title = get_apple_podcast_info(feed)\n",
        "                normalized_feeds.append(rss_url)\n",
        "                feed_info.append((rss_url, podcast_title))\n",
        "                print(f\"   ‚úì RSS Feed: {rss_url}\")\n",
        "                print(f\"   üìª Podcast Title: {podcast_title}\\n\")\n",
        "                apple_podcast_count += 1\n",
        "            except Exception as e:\n",
        "                # Fallback to regular conversion if getting info fails\n",
        "                print(f\"   ‚ö†Ô∏è  Could not get podcast info, using basic conversion...\")\n",
        "                rss_url = normalize_feed_url(feed)\n",
        "                podcast_title = get_podcast_title(rss_url)\n",
        "                normalized_feeds.append(rss_url)\n",
        "                feed_info.append((rss_url, podcast_title))\n",
        "                print(f\"   ‚úì RSS Feed: {rss_url}\")\n",
        "                print(f\"   üìª Podcast Title: {podcast_title}\\n\")\n",
        "                apple_podcast_count += 1\n",
        "        else:\n",
        "            # Already an RSS feed URL, use as-is and get title\n",
        "            normalized_feed = normalize_feed_url(feed)  # Still normalize to validate\n",
        "            podcast_title = get_podcast_title(normalized_feed)\n",
        "            normalized_feeds.append(normalized_feed)\n",
        "            feed_info.append((normalized_feed, podcast_title))\n",
        "            rss_feed_count += 1\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Warning: Error processing feed URL '{feed}': {e}\")\n",
        "        print(f\"   Using original URL as-is (may cause issues if invalid)\\n\")\n",
        "        normalized_feeds.append(feed)  # Use original URL if conversion fails\n",
        "        feed_info.append((feed, \"Unknown Podcast\"))\n",
        "\n",
        "feeds = normalized_feeds\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"üìä Feed Summary:\")\n",
        "print(f\"   Total feeds loaded: {len(feeds)}\")\n",
        "if apple_podcast_count > 0:\n",
        "    print(f\"   Apple Podcast links converted: {apple_podcast_count}\")\n",
        "if rss_feed_count > 0:\n",
        "    print(f\"   RSS feed URLs (direct): {rss_feed_count}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "print(f\"üìª Podcasts Loaded:\")\n",
        "for i, (rss_url, title) in enumerate(feed_info, 1):\n",
        "    print(f\"  {i}. {title}\")\n",
        "    print(f\"     RSS Feed: {rss_url}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All functions are now imported from podcast_fetch package\n",
        "# Functions available:\n",
        "# - normalize(name)\n",
        "# - collect_data(feed)\n",
        "# - summarise_podcasts(df)\n",
        "# - get_rss_from_apple_podcast(apple_url) - Convert Apple Podcast link to RSS feed\n",
        "# - normalize_feed_url(feed_url) - Automatically detect and convert Apple Podcast links\n",
        "# - And many more...\n",
        "\n",
        "# Example usage:\n",
        "# 1. Convert an Apple Podcast link to RSS feed URL:\n",
        "#    apple_url = \"https://podcasts.apple.com/us/podcast/example/id123456789\"\n",
        "#    rss_url = get_rss_from_apple_podcast(apple_url)\n",
        "#\n",
        "# 2. Or use normalize_feed_url() which automatically handles both:\n",
        "#    - Apple Podcast links ‚Üí converts to RSS feed\n",
        "#    - RSS feed URLs ‚Üí returns as-is\n",
        "#    feed_url = normalize_feed_url(any_feed_url)\n",
        "\n",
        "print(\"All PodcastFetch functions are available via imports!\")\n",
        "print(\"\\nüí° Tip: In feeds.txt, you can mix both types:\")\n",
        "print(\"   - Direct RSS feed URLs (e.g., https://example.com/feed.rss)\")\n",
        "print(\"   - Apple Podcast links (e.g., https://podcasts.apple.com/.../id123456789)\")\n",
        "print(\"   Both will be automatically handled!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.data.collection module\n",
        "# Available as: collect_data(feed)\n",
        "# This cell can be removed or used for testing\n",
        "print(\"collect_data() is available from podcast_fetch package\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.data.summary module\n",
        "# Available as: summarise_podcasts(df)\n",
        "# This cell can be removed or used for testing\n",
        "print(\"summarise_podcasts() is available from podcast_fetch package\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All database utility functions are now in podcast_fetch.database module\n",
        "# Available functions:\n",
        "# - clean_dataframe_for_sqlite(df)\n",
        "# - is_valid_database(db_path)\n",
        "# - table_exists(conn, table_name)\n",
        "# - summary_exists(conn, podcast_name)\n",
        "# - add_download_columns_to_table(conn, table_name)\n",
        "# - update_download_info(conn, podcast_name, episode_id, file_path)\n",
        "# - update_all_tables_with_download_columns(conn)\n",
        "print(\"All database utility functions are available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.database.connection module\n",
        "# Available as: is_valid_database(db_path)\n",
        "print(\"is_valid_database() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.database.queries module\n",
        "# Available as: table_exists(conn, table_name)\n",
        "print(\"table_exists() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.database.queries module\n",
        "# Available as: summary_exists(conn, podcast_name)\n",
        "print(\"summary_exists() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.database.schema module\n",
        "# Available as: add_download_columns_to_table(conn, table_name)\n",
        "print(\"add_download_columns_to_table() is available from podcast_fetch package\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.database.schema module\n",
        "# Available as: update_download_info(conn, podcast_name, episode_id, file_path)\n",
        "print(\"update_download_info() is available from podcast_fetch package\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.database.schema module\n",
        "# Available as: update_all_tables_with_download_columns(conn)\n",
        "print(\"update_all_tables_with_download_columns() is available from podcast_fetch package\")\n",
        "\n",
        "# Run this to update existing tables (optional - new tables will have these columns automatically)\n",
        "# update_all_tables_with_download_columns(conn)\n",
        "\n",
        "# Also available: add_indexes_to_table(conn, table_name) and update_all_tables_with_indexes(conn)\n",
        "# Indexes are automatically added when creating new tables, but you can update existing tables:\n",
        "# update_all_tables_with_indexes(conn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code Organization\n",
        "\n",
        "All functions have been extracted to the `podcast_fetch` Python package.\n",
        "\n",
        "**Module Structure:**\n",
        "- `podcast_fetch.config` - Configuration constants\n",
        "- `podcast_fetch.data` - Data collection and processing\n",
        "- `podcast_fetch.database` - Database utilities\n",
        "- `podcast_fetch.download` - Download operations\n",
        "\n",
        "All functions are imported in Cell 1 and available for use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All functions are now in the podcast_fetch package\n",
        "# No manual updates needed - functions are already updated in the modules\n",
        "print(\"All functions are available from podcast_fetch package!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if the database already exists and is valid\n",
        "db_path = config.DB_PATH\n",
        "db_exists = os.path.exists(db_path)\n",
        "\n",
        "if db_exists:\n",
        "    if is_valid_database(db_path):\n",
        "        print(f\"Database '{db_path}' already exists and is valid. Connecting to existing database.\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Database '{db_path}' exists but is corrupted or invalid.\")\n",
        "        print(f\"Creating a new database file...\")\n",
        "        # Backup the corrupted file\n",
        "        backup_path = f\"{db_path}.corrupted_backup\"\n",
        "        if os.path.exists(backup_path):\n",
        "            os.remove(backup_path)\n",
        "        os.rename(db_path, backup_path)\n",
        "        print(f\"Corrupted database backed up to: {backup_path}\")\n",
        "        db_exists = False\n",
        "\n",
        "if not db_exists:\n",
        "    print(f\"Database '{db_path}' does not exist. Creating new database.\")\n",
        "\n",
        "# Connect to the database\n",
        "# Note: For notebook use, we keep the connection open across cells\n",
        "# For production scripts, use the context manager pattern:\n",
        "#   with get_db_connection(db_path) as conn:\n",
        "#       # your code here\n",
        "#   # connection automatically closes\n",
        "\n",
        "# For notebook convenience, create a connection that stays open\n",
        "conn = sqlite3.connect(db_path, timeout=config.DB_TIMEOUT)\n",
        "print(f\"Database connection established.\")\n",
        "print(f\"Note: Use 'conn.close()' when done, or use get_db_connection() context manager in scripts.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify connection is still open and valid\n",
        "try:\n",
        "    conn.execute(\"SELECT 1\")\n",
        "except (sqlite3.ProgrammingError, sqlite3.OperationalError) as e:\n",
        "    print(f\"‚ö†Ô∏è  Database connection error: {e}\")\n",
        "    print(\"Reconnecting to database...\")\n",
        "    db_path = config.DB_PATH\n",
        "    conn = sqlite3.connect(db_path, timeout=config.DB_TIMEOUT)\n",
        "    print(\"‚úì Database reconnected successfully.\")\n",
        "\n",
        "for feed_url in feeds:\n",
        "    # Strip newline characters from the feed URL\n",
        "    feed_url = feed_url.strip()\n",
        "    \n",
        "    # Collect data from the feed\n",
        "    df = collect_data(feed_url)\n",
        "    \n",
        "    # Get the title from the dataframe (it's stored in the 'author' column)\n",
        "    title = df['author'].iloc[0] if len(df) > 0 else 'unknown'\n",
        "\n",
        "    # Verificar si el podcast ya existe y tiene descargas antes de reemplazar\n",
        "    should_skip = False\n",
        "    try:\n",
        "        if table_exists(conn, title) and summary_exists(conn, title):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Podcast '{title}' ya existe en la base de datos.\")\n",
        "            \n",
        "            # Verificar si hay episodios descargados\n",
        "            has_downloads = has_downloaded_episodes(conn, title)\n",
        "            \n",
        "            if has_downloads:\n",
        "                # Verificar si los archivos existen en disco\n",
        "                all_exist, total_downloaded, files_found = verify_downloaded_files_exist(conn, title)\n",
        "                \n",
        "                print(f\"  üìä Estado del podcast:\")\n",
        "                print(f\"    - Episodios descargados en BD: {total_downloaded}\")\n",
        "                print(f\"    - Archivos encontrados en disco: {files_found}\")\n",
        "                \n",
        "                if all_exist and total_downloaded > 0:\n",
        "                    print(f\"  ‚úì Todos los archivos descargados existen en disco.\")\n",
        "                    print(f\"  ‚ö†Ô∏è  No se reemplazar√° la tabla para evitar perder datos de descargas.\")\n",
        "                    print(f\"  üí° Si deseas actualizar, elimina manualmente la tabla '{title}' primero.\")\n",
        "                    print(f\"{'='*60}\\n\")\n",
        "                    should_skip = True\n",
        "                elif files_found < total_downloaded:\n",
        "                    print(f\"  ‚ö†Ô∏è  Algunos archivos no existen en disco ({files_found}/{total_downloaded}).\")\n",
        "                    print(f\"  üîÑ Se actualizar√° la tabla para sincronizar el estado.\")\n",
        "                    print(f\"{'='*60}\\n\")\n",
        "                else:\n",
        "                    print(f\"  ‚ÑπÔ∏è  No hay archivos en disco pero hay registros en BD.\")\n",
        "                    print(f\"  üîÑ Se actualizar√° la tabla.\")\n",
        "                    print(f\"{'='*60}\\n\")\n",
        "            else:\n",
        "                print(f\"  ‚ÑπÔ∏è  No hay episodios descargados.\")\n",
        "                print(f\"  üîÑ Se actualizar√° la tabla normalmente.\")\n",
        "                print(f\"{'='*60}\\n\")\n",
        "    except (sqlite3.OperationalError, sqlite3.ProgrammingError) as e:\n",
        "        print(f\"‚ö†Ô∏è  Error checking podcast status: {e}\")\n",
        "        print(\"Attempting to reconnect...\")\n",
        "        db_path = config.DB_PATH\n",
        "        conn = sqlite3.connect(db_path, timeout=config.DB_TIMEOUT)\n",
        "        print(\"‚úì Reconnected. Skipping verification for this podcast.\")\n",
        "    \n",
        "    # Si hay descargas completas, saltar este podcast\n",
        "    if should_skip:\n",
        "        continue\n",
        "    \n",
        "    # Check if the table already exists before saving\n",
        "    if table_exists(conn, title):\n",
        "        print(f\"Table '{title}' already exists. Replacing with new data.\")\n",
        "    else:\n",
        "        print(f\"Table '{title}' does not exist. Creating new table.\")\n",
        "    \n",
        "    # Clean and save the podcast data\n",
        "    try:\n",
        "        df_clean = clean_dataframe_for_sqlite(df)\n",
        "        df_clean.to_sql(title, conn, if_exists='replace', index=False)\n",
        "        # Add performance indexes after creating/replacing table\n",
        "        add_indexes_to_table(conn, title)\n",
        "    except (sqlite3.OperationalError, sqlite3.ProgrammingError) as e:\n",
        "        print(f\"‚ö†Ô∏è  Error saving podcast data: {e}\")\n",
        "        print(\"Attempting to reconnect...\")\n",
        "        db_path = config.DB_PATH\n",
        "        conn = sqlite3.connect(db_path, timeout=config.DB_TIMEOUT)\n",
        "        df_clean = clean_dataframe_for_sqlite(df)\n",
        "        df_clean.to_sql(title, conn, if_exists='replace', index=False)\n",
        "        # Add performance indexes after creating/replacing table\n",
        "        add_indexes_to_table(conn, title)\n",
        "        print(\"‚úì Data saved after reconnection.\")\n",
        "    \n",
        "    # Summarize the podcasts\n",
        "    df_2 = summarise_podcasts(df)\n",
        "    \n",
        "    # Check if summary for this podcast already exists\n",
        "    try:\n",
        "        if summary_exists(conn, title):\n",
        "            print(f\"Summary for '{title}' already exists. Updating existing summary.\")\n",
        "            # Delete the old summary row before inserting the new one\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"DELETE FROM summary WHERE name=?\", (title,))\n",
        "            conn.commit()\n",
        "            # Now append the new summary\n",
        "            df_2_clean = clean_dataframe_for_sqlite(df_2)\n",
        "            df_2_clean.to_sql('summary', conn, if_exists='append', index=False)\n",
        "        else:\n",
        "            print(f\"Summary for '{title}' does not exist. Creating new summary.\")\n",
        "            # Clean and save the summary (append mode to accumulate summaries from all podcasts)\n",
        "            df_2_clean = clean_dataframe_for_sqlite(df_2)\n",
        "            df_2_clean.to_sql('summary', conn, if_exists='append', index=False)\n",
        "    except (sqlite3.OperationalError, sqlite3.ProgrammingError) as e:\n",
        "        print(f\"‚ö†Ô∏è  Error updating summary: {e}\")\n",
        "        print(\"Attempting to reconnect...\")\n",
        "        db_path = config.DB_PATH\n",
        "        conn = sqlite3.connect(db_path, timeout=config.DB_TIMEOUT)\n",
        "        if summary_exists(conn, title):\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"DELETE FROM summary WHERE name=?\", (title,))\n",
        "            conn.commit()\n",
        "        df_2_clean = clean_dataframe_for_sqlite(df_2)\n",
        "        df_2_clean.to_sql('summary', conn, if_exists='append', index=False)\n",
        "        print(\"‚úì Summary updated after reconnection.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Unexpected error: {e}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.download.utils module\n",
        "# Available as: sanitize_filename(filename)\n",
        "print(\"sanitize_filename() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.download.utils module\n",
        "# Available as: show_podcast_summary(conn, podcast_names)\n",
        "print(\"show_podcast_summary() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.download.downloader module\n",
        "# Available as: download_all_episodes(conn, podcast_name, downloads_folder=None, delay_seconds=None)\n",
        "# Uses config defaults if parameters are None\n",
        "print(\"download_all_episodes() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.download.downloader module\n",
        "# Available as: download_last_episode(conn, podcast_name, downloads_folder=None)\n",
        "# Uses config defaults if parameters are None\n",
        "print(\"download_last_episode() is available from podcast_fetch package\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function moved to podcast_fetch.download.metadata module\n",
        "# Available as: update_summary(conn, podcast_name)\n",
        "print(\"update_summary() is available from podcast_fetch package\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Download all episodes for a podcast\n",
        "# Replace 'cosas_de_internet' with the podcast name you want to download from\n",
        "# download_all_episodes(conn, 'cosas_de_internet')\n",
        "\n",
        "# Or download all episodes for all podcasts\n",
        "# First, collect all podcast names\n",
        "podcast_names = []\n",
        "for feed_url in feeds:\n",
        "    df = collect_data(feed_url)\n",
        "    title = df['author'].iloc[0] if len(df) > 0 else 'unknown'\n",
        "    podcast_names.append(title)\n",
        "\n",
        "# Show summary of all podcasts\n",
        "if podcast_names:\n",
        "    summary = show_podcast_summary(conn, podcast_names)\n",
        "    \n",
        "    # Ask for overall confirmation\n",
        "    total = sum(summary.values())\n",
        "    if total > 0:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        user_input = input(f\"Do you want to proceed with downloading {total} episode(s) across {len(podcast_names)} podcast(s)? (yes/no): \").strip().lower()\n",
        "        print(f\"{'='*70}\\n\")\n",
        "        \n",
        "        if user_input in ['yes', 'y']:\n",
        "            # Download episodes for each podcast\n",
        "            for podcast_name in podcast_names:\n",
        "                if summary.get(podcast_name, 0) > 0:\n",
        "                    download_all_episodes(conn, podcast_name)\n",
        "        else:\n",
        "            print(\"Download cancelled by user.\")\n",
        "    else:\n",
        "        print(\"All episodes are already downloaded!\")\n",
        "\n",
        "# When done with all operations, close the connection\n",
        "conn.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
